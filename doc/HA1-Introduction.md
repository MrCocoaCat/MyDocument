()[]https://docs.openstack.org/ha-guide/
### OpenStack高可用介绍
高可用系统力求将以下问题最小化
1. 系统停机时间：用户所使用的服务器在一段时间内无法使用
2. 数据丢失：数据被意外删除或销毁
大多数高可用系统在单个故障生时可以提供保护，即防止关机或数据丢失。然后进行故障联防是十分必要的，即防止单个故障恶化为更严重的后续故障。许多服务提供Service Level Agreement (SLA)，其中包括计算服务的正常运行时间百分比，该百分比是根据可用时间和系统停机时间(不包括计划停机时间)计算的。

正常运行时间=可用时间/停机时间

####冗余和故障转移（Redundancy and failover）
高可用性是通过运行每个服务的冗余实例的冗余硬件实现的。
如果运行一个服务实例的硬件部分发生故障，系统就可以进行故障转移，以使用运行在没有发生故障的硬件上的另一个服务实例。高可用性的一个关键方面是消除单点故障(SPOFs)。
SPOF是一种单独的设备或软件，如果出现故障，会导致系统停机或数据丢失。为了消除SPOFs，检查是否存在冗余机制:
* 网络组件，如交换机和路由器
* 应用程序和自动服务迁移
* 存储组件
* 电力、空调、消防等服务设施
如果组件发生故障，备份系统必须承担其负载，大多数高可用性系统将尽快替换失败的组件，以保持必要的冗余。这样，在降级保护状态下所花费的时间就会最小化。
大多数高可用性系统在出现多个独立故障时而引发整体性故障的情况下，**倾向于保护数据而不是维护可用性。**
高可用性系统通常可实现 *99.99％* 或更高的正常运行时间百分比，这大致相当于 *每年不到一小时* 的累计停机时间。 为了实现这一目标，高可用性系统应该在故障发生后将恢复时间保持在大约 *一到两分钟*，有时甚至更少。OpenStack目前满足其自身基础架构服务的可用性要求，这意味着OpenStack基础架构正常运行99.99％的正常运行时间。 但是，OpenStack不保证单个访问实例的99.99％可用性。
本文档讨论了实现高可用性系统的一些常用方法，重点是核心OpenStack服务以及与OpenStack紧密结合的其他开源服务。

您需要解决在OpenStack环境中运行的任何应用程序软件的高可用性问题，重要的是确保您的服务冗余且可用。

#### 无状态和有状态服务(Stateless versus stateful services)

以下是无状态和有状态服务的定义:

* 无状态服务（Stateless）

在您的请求之后提供响应的服务，然后不需要进一步关注。要使无状态的服务高度可用，需要提供冗余实例并平衡它们的负载。无状态的OpenStack服务包括nova-api、nova-conductor、gls -api、keystone-api、neutron-api和nova-scheduler。

有状态服务(stateful)

服务的后续请求依赖于第一个请求的结果。有状态服务更难管理，因为单个操作通常涉及多个请求。提供额外的实例和负载平衡并不能解决问题。例如，horizon用户界面每次进入新页面时都自动重置。有状态的OpenStack服务包括OpenStack数据库和消息队列。使有状态服务高可用性取决于您选择的是Active/passive配置还是active/active配置。

#### Active/passive versus active/active

有状态服务(stateful)可以配置为 active/passive 或 ctive/active，其定义如下:

* active/passive configuration

**维护可在活动服务失败时联机的冗余实例**。 例如，OpenStack在维护灾难恢复数据库的同时写入主数据库，如果主数据库发生故障，该数据库可以联机。有状态服务的典型 active/passive 安装和维护可在需要时联机的替换资源。 使用虚拟IP地址（VIP）处理请求，这有助于以最小的重新配置返回服务。 单独的应用程序（如Pacemaker或Corosync）会监视这些服务，并在必要时将备份联机。

>故障节点上的访问请求或自动转到另外一个正常运行节点上，或通过负载均衡器在剩余的正常运行的节点上进行负载均衡。这种模式下集群中的节点通常部署了相同的软件并具有相同的参数配置，同时各服务在这些节点上并行运行。

* active/active configuration

**每个服务均具有一份，其同时管理主系统和冗余系统**。发生故障時，用户可能並不会觉察。 在主系统修复之前,备份系统已经在线运行,并承担所提高的负载。

通常，无状态服务的 active/active 安装维护冗余实例，并使用虚拟IP地址和负载平衡器（如HAProxy）对请求进行负载平衡。

有状态服务的典型 active/active 安装包括冗余服务，所有实例具有相同的状态。
换句话说，对数据库的一个实例的更新会更新所有其他实例。
这样，对一个实例的请求与对任何其他实例的请求相同。 负载均衡器管理这些系统的流量，确保操作系统始终处理请求。

>每个节点上都部署有相同的服务实例，但是正常情况下只有一个节点上的服务实例处于激活状态，只有当前活动节点发生故障后，另外的处于 standby状态的节点上的服务才会被激活，这种模式通常意味着需要部署额外的且正常情况下不承载负载的硬件。

#### 集群及数量 Clusters and quorums

quorum指定冗余节点集群中必须具有功能的节点的最小数量，以便集群保持功能。当一个节点发生故障，故障转移将控制转移到其他节点时，系统必须确保数据和进程保持正常。为了确定这一点，将比较剩余节点的内容，如果存在差异，则执行一个多数规则算法。因此，高可用性环境中的每个集群都应该有 *奇数个节点*，并且quorum定义为超过一半的节点。如果多个节点失败，以致集群大小低于仲裁值，那么集群本身就会失败。
例如，在一个7节点集群中，应该将quorum设置为floor(7/2) + 1 == 4。如果quorum是4，同时有4个节点失败，那么集群本身就会失败，而如果不超过3个节点失败，它将继续运行。如果分别划分为3个和4个节点的分区，那么4个节点的quorum将继续操作多数分区，并停止或隔离少数分区(取决于无quorum-policy集群配置)。

当四个节点同时失败时，集群也将继续工作。但是，如果分别划分为3个节点和4个节点，那么3个节点的quorum将使双方都试图隔离其他节点和主机资源。如果不启用隔离，将直接运行每个资源的两个副本。
这就是为什么将quorum设置为小于floor(n/2) + 1是危险的。但是，对于某些特定的情况，可能需要这样做，例如在一个节点上，我们100%确定其他节点已经关闭了。在作为研究或演示而配置OpenStack环境时，可以关闭quorum检查。生产环境下应该在启用quorum的情况下运行。

#### Single-controller高可用性模式

OpenStack支持由管理高可用性环境的服务管理的单控制器高可用性模式，但实际上不是高可用性模式，因为没有配置冗余控制器用于故障转移。此环境可用于研究和演示，但不适用于生产环境。可以向这样的环境添加控制器，将其转换为真正高可用的环境。高可用性并不是对每个用户都适用。它带来了一些挑战。对于具有大量数据的数据库或系统来说，高可用性可能过于复杂。复制会减慢大型系统的速度。






### 配置计算节点
安装指南提供了安装多个计算节点的说明。要使计算节点高度可用，您必须配置环境，使其包含API和其他服务的多个实例。
#### 为实例配置高可用性
截至2016年9月，OpenStack高可用社区正在设计和开发一种官方的、统一的方式来为实例提供高可用性。我们正在开发从计算节点上的硬件或与管理程序相关的软件故障中自动恢复，或其他可能阻止实例正常运行的故障，例如煤渣卷I/O路径问题。

更多的细节可以在OpenStack的HA社区和产品工作组(PWG)共同编写的用户故事中找到，其中这个特性被认为是OpenStack中缺失的功能，应该以高度优先的方式处理。
